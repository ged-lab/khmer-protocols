Mapping reads to the transcriptome with TopHat
==============================================

.. shell start

Now that we have some quality-controlled reads, we're going to *map* the
reads to the reference gene set, for the purpose of counting how many
reads have come from each gene.  We'll be using the `TopHat software
<http://ccb.jhu.edu/software/tophat/manual.shtml>`__

.. note:: This section reuires TopHat2/2.0.13, Bowtie/2.2.3.0 and Samtools/0.1.19.0 installed

Download the Bowtie2 index
-------------------------- 

TopHat is built on the short read mapping program `Bowtie 
<http://bowtie-bio.sourceforge.net/index.shtml>`__. Bowtie indexes the genome 
with a Burrows-Wheeler index to keep its memory footprint small. 
We can build those indexes for our genome using `bowtie2-build 
<http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#the-bowtie2-build-indexer>`__.
However for most if not all model organisms, you can download the Bowtie index for 
a given genome assembly. 

The `Illumina iGenomes project <http://cufflinks.cbcb.umd.edu/igenomes.html>`__ 
provided the RNA-Seq user community with a set of genome sequence indexes (including Bowtie indexes).  

We will download the iGenome index for the UCSC hg19 assembly version. 

.. check if the data directory exists
.. ::

   if [ ! -d "$workingPath/Homo_sapiens" ]; then

::

        cd $workingPath
        wget ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Homo_sapiens/UCSC/hg19/Homo_sapiens_UCSC_hg19.tar.gz
        tar -zxvf Homo_sapiens_UCSC_hg19.tar.gz
 
.. ::

   fi

.. note::

   The homo sapians iGenome tarball is huge (~20 GiB). I have prepared a smaller version containing the minimal required files. 
   This file is stored in Amazon S3. To use this file replace the last 3 lines of code with::

        cd $workingPath
        wget https://s3.amazonaws.com/reftransdata/Homo_sapiens_UCSC_hg19_small.tar.gz
        tar -zxvf Homo_sapiens_UCSC_hg19_small.tar.gz
        mv Homo_sapiens2 Homo_sapiens
    
..   for more details about creating and using this file, check this file:  :doc:`./igenome-backup`
   

Define the path of the genome and genome_index_base which is the name of any 
of the index files up to but not including the first period.

::

        homo_sapiens_genome="$workingPath/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/genome.fa"
        Bowtie2Index="$workingPath/Homo_sapiens/UCSC/hg19/Sequence/Bowtie2Index/genome"
 
 
Making use of gene model annotations
------------------------------------
Model organisms usually have a good annotation of their transcriptome. Annotation 
information is typically shared in GTF files. Illumina iGenomes indexes come 
with GTF transcript annotation files (Congratualtion, this means you have downloaded them already)
Let us define the path of the required GTF in the downloaded iGenome package
::

   GTF_file="$workingPath/Homo_sapiens/UCSC/hg19/Annotation/Genes/genes.gtf" 
   
.. Note::
   The human genome is compased of multi fasta entries for chr1-22, M, X,and Y. 
   genes.gtf has some non canonical chromosomal headers e.g. chr17_ctg5_hap1, chr17_gl000205_random, 
   chrUn_gl000228, and many more. You can learn more about these header from this 
   `discussion <https://www.biostars.org/p/7629/>`__ . These header will cause some software to 
   through some warning messages. Do not worry about it :) 

We can pass the annotation file to TopHat through the optional argument (--GTF). 
TopHat will first extract the transcript sequences and use Bowtie to align reads to this virtual transcriptome first. 
Only the reads that do not fully map to the transcriptome will then be mapped on the genome.

For TopHat to make use of GTF file, it has to create a Bowtie index for the transcriptome 
sequences which could be time consuming. If you are aligning multiple samples with TopHat, 
we can create these indexes once and reused for multiple and even *simultaneous* TopHat runs.
To create the transcriptome-index, we can inovke TopHat without input reads
::

   tophat \
       --num-threads 1 \
       --GTF "$GTF_file" \
       --transcriptome-index "$workingPath/trans_Index/transcriptome" \
       $Bowtie2Index

   
Prepare the input reads
-----------------------
You can pass these two PE files directly to the TopHat to do the pair end orinted alignment. 
TopHat allows the use of additional unpaired reads but it has to pass as a single file. 
So we need to merge every two SE files belonging to the same sample
::

   for f in *R1.se*; do
        input_R1="$f"
        input_R2=$(echo "$f" | sed s/R1/R2/)				                
        output=$(echo "$f" | sed s/R1/R/)
        cat $input_R1 $input_R2 > $output
   done

Mapping reads
-------------

And now run TopHat on one sample::

   tophat \
       --num-threads 2 \
       --GTF "$GTF_file" \
       --transcriptome-index "$workingPath/trans_Index/transcriptome" \
       --output-dir salivary_repl1_tophat \
       $Bowtie2Index \
       salivary_repl1_R1.pe.fq.gz salivary_repl1_R2.pe.fq.gz,salivary_repl1_R.se.fq.gz 

This will take about ~10-15 minutes. We can run all the samples sequencially using a for loop.
::

   for f in *R1.pe*; do
        input_R1="$f"
        input_R2=$(echo "$f" | sed s/R1/R2/)
        input_R=$(echo "$f" | sed s/R1.pe/R.se/)
        output=$(basename "$f" | cut -f 1,2 -d "_")_tophat
        tophat \
            --num-threads 1 \
            --GTF "$GTF_file" \
            --transcriptome-index "$workingPath/trans_Index/transcriptome" \
            --output-dir $output \
            $Bowtie2Index \
            $input_R1 $input_R2,$input_R 
   done

.. Note::

   With large input files, TopHat will take hours and may be days. You can increase the 
   number of threads but make sure that you have the required underlying resources.   
   It will be more efficient to run TopHat on all samples in parallel jobs. On Amazon AWS, 
   you can run multiple instances. For HPC, you can submet multiple jobs simultaneously. 
   
   :doc:`./m-HPC-tophat`


The output will be a folder for each sample names like <sample-name>_tophat. Each folder contain multiple files

1. accepted_hits.bam:  The main output file with contains the read alignment in `SAM <http://samtools.sourceforge.net/>`__ format.
2. unmapped.bam: Another file in the same format but contains only the unmapped reads
3. junctions.bed, insertions.bed, deletions.bed: A `UCSC BED track <http://genome.ucsc.edu/FAQ/FAQformat.html#format1>`__ of junctions, insertions and deletions reported by TopHat
4. align_summary.txt: a text file that contains summry statistics about the mapped reads


Counting mapped reads percentage
--------------------------------

You can open the align_summary file in any out folder ::

   vim salivary_repl1_tophat/align_summary.txt

We can calculte these statistics ourselves. Let's ask samtools for the total number of reads that mapped. 
We count all the alignment in the BAM file but exclude unmapped reads (-F 4) and also exclude non primary alignments (-F 256)::

   samtools view -c -F 4 -F 256 salivary_repl1_tophat/accepted_hits.bam

You should get around 170,849.  

We can count the reads in our input files::
   
   R1_pe="$(zcat salivary_repl1_R1.pe.fq.gz | echo $((`wc -l`/4)))"
   R2_pe="$(zcat salivary_repl1_R2.pe.fq.gz | echo $((`wc -l`/4)))"
   R_se="$(zcat salivary_repl1_R.se.fq.gz | echo $((`wc -l`/4)))"
   echo $((R1_pe + R2_pe + R_se))

You should get around 189,150

So you have 170,849 mapped reads out of 189,150 -- about 90.3%.  That's pretty good!

.. shell stop

----

Next: :doc:`m-count`
